====================TaintedSinkInfo:=======================
-------------TaintedSinkInfo----------
fileName:	DataNode.java	methodSinagture:	org.apache.hadoop.hdfs.server.datanode.DataNode.initDirectoryScanner(Lorg/apache/hadoop/conf/Configuration;)V	methodLines:	1407:1426
blockLines:	1412:-1
paras:	null
TaintedStat:	NORMAL initDirectoryScanner:conditional branch(ge, to iindex=19) 12,13 Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, initDirectoryScanner(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere
Source:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, initDirectoryScanner(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere[11]10 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getTimeDuration(Ljava/lang/String;JLjava/util/concurrent/TimeUnit;)J > 2,6,7,8 @20 exception:9
Tainted Path:	NORMAL_RET_CALLER:Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, initDirectoryScanner(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere[11]10 = invokevirtual < Application, Lorg/apache/hadoop/conf/Configuration, getTimeDuration(Ljava/lang/String;JLjava/util/concurrent/TimeUnit;)J > 2,6,7,8 @20 exception:9
NORMAL initDirectoryScanner:12 = compare 10,11 opcode=cmp Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, initDirectoryScanner(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere
NORMAL initDirectoryScanner:conditional branch(ge, to iindex=19) 12,13 Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, initDirectoryScanner(Lorg/apache/hadoop/conf/Configuration;)V > Context: Everywhere



====================ExtendedBlocks:=======================


====================MethodSrc:=======================
  private synchronized void initDirectoryScanner(Configuration conf) {
    if (directoryScanner != null) {
      return;
    }
    String reason = null;
    if (conf.getTimeDuration(DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY,
        DFS_DATANODE_DIRECTORYSCAN_INTERVAL_DEFAULT, TimeUnit.SECONDS) < 0) {
      reason = "verification is turned off by configuration";
    } else if ("SimulatedFSDataset".equals(data.getClass().getSimpleName())) {
      reason = "verifcation is not supported by SimulatedFSDataset";
    } 
    if (reason == null) {
      directoryScanner = new DirectoryScanner(data, conf);
      directoryScanner.start();
    } else {
      LOG.warn("Periodic Directory Tree Verification scan " +
              "is disabled because {}",
          reason);
    }
  }
  


====================ctx:=======================
CtxCodeBlock{node=Node: < Application, Lorg/apache/hadoop/hdfs/server/datanode/DataNode, initBlockPool(Lorg/apache/hadoop/hdfs/server/datanode/BPOfferService;)V > Context: Everywhere, blocks=[BB[SSA:55..55]29 - org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(Lorg/apache/hadoop/hdfs/server/datanode/BPOfferService;)V, BB[SSA:52..54]28 - org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(Lorg/apache/hadoop/hdfs/server/datanode/BPOfferService;)V, BB[SSA:56..58]30 - org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(Lorg/apache/hadoop/hdfs/server/datanode/BPOfferService;)V, BB[SSA:-1..-2]34 - org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(Lorg/apache/hadoop/hdfs/server/datanode/BPOfferService;)V], numberOfBasicBlocks=4, firstLineNumber=2006, lastLineNumber=2007, firstMethodNumber=1981, lastMethodNumber=2008, isFirstLineValid=true, methodSrcCode=
  void initBlockPool(BPOfferService bpos) throws IOException {
    NamespaceInfo nsInfo = bpos.getNamespaceInfo();
    if (nsInfo == null) {
      throw new IOException("NamespaceInfo not found: Block pool " + bpos
          + " should have retrieved namespace info before initBlockPool.");
    }
    
    setClusterId(nsInfo.clusterID, nsInfo.getBlockPoolID());

    // Register the new block pool with the BP manager.
    blockPoolManager.addBlockPool(bpos);
    
    // In the case that this is the first block pool to connect, initialize
    // the dataset, block scanners, etc.
    initStorage(nsInfo);

    try {
      data.addBlockPool(nsInfo.getBlockPoolID(), getConf());
    } catch (AddBlockPoolException e) {
      handleAddBlockPoolError(e);
    }
    // HDFS-14993: check disk after add the block pool info.
    checkDiskError();

    blockScanner.enableBlockPoolId(bpos.getBlockPoolId());
    initDirectoryScanner(getConf());
    initDiskBalancer(data, getConf());
  }

}
