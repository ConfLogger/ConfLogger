select <line#> and insert log level and Log verbosity message after <line#>

Query: Target method code:
<Line#0>public static int getCompletionPollInterval(Configuration conf) {
<Line#1>int completionPollIntervalMillis = conf.getInt(
<Line#2>COMPLETION_POLL_INTERVAL_KEY, DEFAULT_COMPLETION_POLL_INTERVAL);
<Line#3>if (completionPollIntervalMillis < 1) {
<Line#4>completionPollIntervalMillis = DEFAULT_COMPLETION_POLL_INTERVAL;
<Line#5>}
<Line#6>return completionPollIntervalMillis;
<Line#7>}

Example 1:
<Line#1>{
<Line#2>  try {
<Line#3>    Configuration conf=job.getConfiguration();
<Line#4>    if (conf.getBoolean(CREATE_DIR,false)) {
<Line#5>      FileSystem fs=FileSystem.get(conf);
<Line#6>      Path inputPaths[]=FileInputFormat.getInputPaths(job);
<Line#7>      for (int i=0; i < inputPaths.length; i++) {
<Line#8>        if (!fs.exists(inputPaths[i])) {
<Line#9>          try {
<Line#10>            fs.mkdirs(inputPaths[i]);
<Line#11>          }
<Line#12> catch (          IOException e) {
<Line#13>          }
<Line#14>        }
<Line#15>      }
<Line#16>    }
<Line#17>    job.submit();
<Line#18>    this.state=State.RUNNING;
<Line#19>  }
<Line#20> catch (  Exception ioe) {
<Line#21>    LOG.info(getJobName() + " got an error while submitting ",ioe);
<Line#22>    this.state=State.FAILED;
<Line#23>    this.message=StringUtils.stringifyException(ioe);
<Line#24>  }
<Line#25>}
Label: <Line#21> LOG.info(getJobName() + " got an error while submitting ",ioe)

Example 2:
<Line#1>{
<Line#2>  int maxAttemptsOnFailure=isCommitJobRepeatable(context) ? context.getConfiguration().getInt(FILEOUTPUTCOMMITTER_FAILURE_ATTEMPTS,FILEOUTPUTCOMMITTER_FAILURE_ATTEMPTS_DEFAULT) : 1;
<Line#3>  int attempt=0;
<Line#4>  boolean jobCommitNotFinished=true;
<Line#5>  while (jobCommitNotFinished) {
<Line#6>    try {
<Line#7>      commitJobInternal(context);
<Line#8>      jobCommitNotFinished=false;
<Line#9>    }
<Line#10> catch (    Exception e) {
<Line#11>      if (++attempt >= maxAttemptsOnFailure) {
<Line#12>        throw e;
<Line#13>      }
<Line#14> else {
<Line#15>        LOG.warn("Exception get thrown in job commit, retry (" + attempt + ") time.",e);
<Line#16>      }
<Line#17>    }
<Line#18>  }
<Line#19>}
Label: <Line#15> LOG.warn("Exception get thrown in job commit, retry (" + attempt + ") time.",e)

Example 3:
<Line#1>{
<Line#2>  createJobClassLoader(conf);
<Line#3>  initJobCredentialsAndUGI(conf);
<Line#4>  dispatcher=createDispatcher();
<Line#5>  addIfService(dispatcher);
<Line#6>  taskAttemptFinishingMonitor=createTaskAttemptFinishingMonitor(dispatcher.getEventHandler());
<Line#7>  addIfService(taskAttemptFinishingMonitor);
<Line#8>  context=new RunningAppContext(conf,taskAttemptFinishingMonitor);
<Line#9>  appName=conf.get(MRJobConfig.JOB_NAME,"<missing app name>");
<Line#10>  conf.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,appAttemptID.getAttemptId());
<Line#11>  newApiCommitter=false;
<Line#12>  jobId=MRBuilderUtils.newJobId(appAttemptID.getApplicationId(),appAttemptID.getApplicationId().getId());
<Line#13>  int numReduceTasks=conf.getInt(MRJobConfig.NUM_REDUCES,0);
<Line#14>  if ((numReduceTasks > 0 && conf.getBoolean("mapred.reducer.new-api",false)) || (numReduceTasks == 0 && conf.getBoolean("mapred.mapper.new-api",false))) {
<Line#15>    newApiCommitter=true;
<Line#16>    LOG.info("Using mapred newApiCommitter.");
<Line#17>  }
<Line#18>  boolean copyHistory=false;
<Line#19>  committer=createOutputCommitter(conf);
<Line#20>  try {
<Line#21>    String user=UserGroupInformation.getCurrentUser().getShortUserName();
<Line#22>    Path stagingDir=MRApps.getStagingAreaDir(conf,user);
<Line#23>    FileSystem fs=getFileSystem(conf);
<Line#24>    boolean stagingExists=fs.exists(stagingDir);
<Line#25>    Path startCommitFile=MRApps.getStartJobCommitFile(conf,user,jobId);
<Line#26>    boolean commitStarted=fs.exists(startCommitFile);
<Line#27>    Path endCommitSuccessFile=MRApps.getEndJobCommitSuccessFile(conf,user,jobId);
<Line#28>    boolean commitSuccess=fs.exists(endCommitSuccessFile);
<Line#29>    Path endCommitFailureFile=MRApps.getEndJobCommitFailureFile(conf,user,jobId);
<Line#30>    boolean commitFailure=fs.exists(endCommitFailureFile);
<Line#31>    if (!stagingExists) {
<Line#32>      isLastAMRetry=true;
<Line#33>      LOG.info("Attempt num: " + appAttemptID.getAttemptId() + " is last retry: "+ isLastAMRetry+ " because the staging dir doesn't exist.");
<Line#34>      errorHappenedShutDown=true;
<Line#35>      forcedState=JobStateInternal.ERROR;
<Line#36>      shutDownMessage="Staging dir does not exist " + stagingDir;
<Line#37>      LOG.error(shutDownMessage);
<Line#38>    }
<Line#39> else     if (commitStarted) {
<Line#40>      errorHappenedShutDown=true;
<Line#41>      isLastAMRetry=true;
<Line#42>      LOG.info("Attempt num: " + appAttemptID.getAttemptId() + " is last retry: "+ isLastAMRetry+ " because a commit was started.");
<Line#43>      copyHistory=true;
<Line#44>      if (commitSuccess) {
<Line#45>        shutDownMessage="Job commit succeeded in a prior MRAppMaster attempt " + "before it crashed. Recovering.";
<Line#46>        forcedState=JobStateInternal.SUCCEEDED;
<Line#47>      }
<Line#48> else       if (commitFailure) {
<Line#49>        shutDownMessage="Job commit failed in a prior MRAppMaster attempt " + "before it crashed. Not retrying.";
<Line#50>        forcedState=JobStateInternal.FAILED;
<Line#51>      }
<Line#52> else {
<Line#53>        if (isCommitJobRepeatable()) {
<Line#54>          errorHappenedShutDown=false;
<Line#55>          cleanupInterruptedCommit(conf,fs,startCommitFile);
<Line#56>        }
<Line#57> else {
<Line#58>          shutDownMessage="Job commit from a prior MRAppMaster attempt is " + "potentially in progress. Preventing multiple commit executions";
<Line#59>          forcedState=JobStateInternal.ERROR;
<Line#60>        }
<Line#61>      }
<Line#62>    }
<Line#63>  }
<Line#64> catch (  IOException e) {
<Line#65>    throw new YarnRuntimeException("Error while initializing",e);
<Line#66>  }
<Line#67>  if (errorHappenedShutDown) {
<Line#68>    NoopEventHandler eater=new NoopEventHandler();
<Line#69>    dispatcher.register(JobEventType.class,eater);
<Line#70>    EventHandler<JobHistoryEvent> historyService=null;
<Line#71>    if (copyHistory) {
<Line#72>      historyService=createJobHistoryHandler(context);
<Line#73>      dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,historyService);
<Line#74>    }
<Line#75> else {
<Line#76>      dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,eater);
<Line#77>    }
<Line#78>    if (copyHistory) {
<Line#79>      addService(createStagingDirCleaningService());
<Line#80>    }
<Line#81>    containerAllocator=createContainerAllocator(null,context);
<Line#82>    addIfService(containerAllocator);
<Line#83>    dispatcher.register(ContainerAllocator.EventType.class,containerAllocator);
<Line#84>    if (copyHistory) {
<Line#85>      addIfService(historyService);
<Line#86>      JobHistoryCopyService cpHist=new JobHistoryCopyService(appAttemptID,dispatcher.getEventHandler());
<Line#87>      addIfService(cpHist);
<Line#88>    }
<Line#89>  }
<Line#90> else {
<Line#91>    clientService=createClientService(context);
<Line#92>    clientService.init(conf);
<Line#93>    containerAllocator=createContainerAllocator(clientService,context);
<Line#94>    committerEventHandler=createCommitterEventHandler(context,committer);
<Line#95>    addIfService(committerEventHandler);
<Line#96>    callWithJobClassLoader(conf,new Action<Void>(){
<Line#97>      public Void call(      Configuration conf){
<Line#98>        preemptionPolicy=createPreemptionPolicy(conf);
<Line#99>        preemptionPolicy.init(context);
<Line#100>        return null;
<Line#101>      }
<Line#102>    }
<Line#103>);
<Line#104>    taskAttemptListener=createTaskAttemptListener(context,preemptionPolicy);
<Line#105>    addIfService(taskAttemptListener);
<Line#106>    EventHandler<JobHistoryEvent> historyService=createJobHistoryHandler(context);
<Line#107>    dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,historyService);
<Line#108>    this.jobEventDispatcher=new JobEventDispatcher();
<Line#109>    dispatcher.register(JobEventType.class,jobEventDispatcher);
<Line#110>    dispatcher.register(TaskEventType.class,new TaskEventDispatcher());
<Line#111>    dispatcher.register(TaskAttemptEventType.class,new TaskAttemptEventDispatcher());
<Line#112>    dispatcher.register(CommitterEventType.class,committerEventHandler);
<Line#113>    if (conf.getBoolean(MRJobConfig.MAP_SPECULATIVE,false) || conf.getBoolean(MRJobConfig.REDUCE_SPECULATIVE,false)) {
<Line#114>      speculator=createSpeculator(conf,context);
<Line#115>      addIfService(speculator);
<Line#116>    }
<Line#117>    speculatorEventDispatcher=new SpeculatorEventDispatcher(conf);
<Line#118>    dispatcher.register(Speculator.EventType.class,speculatorEventDispatcher);
<Line#119>    addService(createStagingDirCleaningService());
<Line#120>    addIfService(containerAllocator);
<Line#121>    dispatcher.register(ContainerAllocator.EventType.class,containerAllocator);
<Line#122>    containerLauncher=createContainerLauncher(context);
<Line#123>    addIfService(containerLauncher);
<Line#124>    dispatcher.register(ContainerLauncher.EventType.class,containerLauncher);
<Line#125>    addIfService(historyService);
<Line#126>  }
<Line#127>  super.serviceInit(conf);
<Line#128>}
Label: <Line#16> LOG.info("Using mapred newApiCommitter.")

Example 4:
<Line#1>{
<Line#2>  createJobClassLoader(conf);
<Line#3>  initJobCredentialsAndUGI(conf);
<Line#4>  dispatcher=createDispatcher();
<Line#5>  addIfService(dispatcher);
<Line#6>  taskAttemptFinishingMonitor=createTaskAttemptFinishingMonitor(dispatcher.getEventHandler());
<Line#7>  addIfService(taskAttemptFinishingMonitor);
<Line#8>  context=new RunningAppContext(conf,taskAttemptFinishingMonitor);
<Line#9>  appName=conf.get(MRJobConfig.JOB_NAME,"<missing app name>");
<Line#10>  conf.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,appAttemptID.getAttemptId());
<Line#11>  newApiCommitter=false;
<Line#12>  jobId=MRBuilderUtils.newJobId(appAttemptID.getApplicationId(),appAttemptID.getApplicationId().getId());
<Line#13>  int numReduceTasks=conf.getInt(MRJobConfig.NUM_REDUCES,0);
<Line#14>  if ((numReduceTasks > 0 && conf.getBoolean("mapred.reducer.new-api",false)) || (numReduceTasks == 0 && conf.getBoolean("mapred.mapper.new-api",false))) {
<Line#15>    newApiCommitter=true;
<Line#16>    LOG.info("Using mapred newApiCommitter.");
<Line#17>  }
<Line#18>  boolean copyHistory=false;
<Line#19>  committer=createOutputCommitter(conf);
<Line#20>  try {
<Line#21>    String user=UserGroupInformation.getCurrentUser().getShortUserName();
<Line#22>    Path stagingDir=MRApps.getStagingAreaDir(conf,user);
<Line#23>    FileSystem fs=getFileSystem(conf);
<Line#24>    boolean stagingExists=fs.exists(stagingDir);
<Line#25>    Path startCommitFile=MRApps.getStartJobCommitFile(conf,user,jobId);
<Line#26>    boolean commitStarted=fs.exists(startCommitFile);
<Line#27>    Path endCommitSuccessFile=MRApps.getEndJobCommitSuccessFile(conf,user,jobId);
<Line#28>    boolean commitSuccess=fs.exists(endCommitSuccessFile);
<Line#29>    Path endCommitFailureFile=MRApps.getEndJobCommitFailureFile(conf,user,jobId);
<Line#30>    boolean commitFailure=fs.exists(endCommitFailureFile);
<Line#31>    if (!stagingExists) {
<Line#32>      isLastAMRetry=true;
<Line#33>      LOG.info("Attempt num: " + appAttemptID.getAttemptId() + " is last retry: "+ isLastAMRetry+ " because the staging dir doesn't exist.");
<Line#34>      errorHappenedShutDown=true;
<Line#35>      forcedState=JobStateInternal.ERROR;
<Line#36>      shutDownMessage="Staging dir does not exist " + stagingDir;
<Line#37>      LOG.error(shutDownMessage);
<Line#38>    }
<Line#39> else     if (commitStarted) {
<Line#40>      errorHappenedShutDown=true;
<Line#41>      isLastAMRetry=true;
<Line#42>      LOG.info("Attempt num: " + appAttemptID.getAttemptId() + " is last retry: "+ isLastAMRetry+ " because a commit was started.");
<Line#43>      copyHistory=true;
<Line#44>      if (commitSuccess) {
<Line#45>        shutDownMessage="Job commit succeeded in a prior MRAppMaster attempt " + "before it crashed. Recovering.";
<Line#46>        forcedState=JobStateInternal.SUCCEEDED;
<Line#47>      }
<Line#48> else       if (commitFailure) {
<Line#49>        shutDownMessage="Job commit failed in a prior MRAppMaster attempt " + "before it crashed. Not retrying.";
<Line#50>        forcedState=JobStateInternal.FAILED;
<Line#51>      }
<Line#52> else {
<Line#53>        if (isCommitJobRepeatable()) {
<Line#54>          errorHappenedShutDown=false;
<Line#55>          cleanupInterruptedCommit(conf,fs,startCommitFile);
<Line#56>        }
<Line#57> else {
<Line#58>          shutDownMessage="Job commit from a prior MRAppMaster attempt is " + "potentially in progress. Preventing multiple commit executions";
<Line#59>          forcedState=JobStateInternal.ERROR;
<Line#60>        }
<Line#61>      }
<Line#62>    }
<Line#63>  }
<Line#64> catch (  IOException e) {
<Line#65>    throw new YarnRuntimeException("Error while initializing",e);
<Line#66>  }
<Line#67>  if (errorHappenedShutDown) {
<Line#68>    NoopEventHandler eater=new NoopEventHandler();
<Line#69>    dispatcher.register(JobEventType.class,eater);
<Line#70>    EventHandler<JobHistoryEvent> historyService=null;
<Line#71>    if (copyHistory) {
<Line#72>      historyService=createJobHistoryHandler(context);
<Line#73>      dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,historyService);
<Line#74>    }
<Line#75> else {
<Line#76>      dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,eater);
<Line#77>    }
<Line#78>    if (copyHistory) {
<Line#79>      addService(createStagingDirCleaningService());
<Line#80>    }
<Line#81>    containerAllocator=createContainerAllocator(null,context);
<Line#82>    addIfService(containerAllocator);
<Line#83>    dispatcher.register(ContainerAllocator.EventType.class,containerAllocator);
<Line#84>    if (copyHistory) {
<Line#85>      addIfService(historyService);
<Line#86>      JobHistoryCopyService cpHist=new JobHistoryCopyService(appAttemptID,dispatcher.getEventHandler());
<Line#87>      addIfService(cpHist);
<Line#88>    }
<Line#89>  }
<Line#90> else {
<Line#91>    clientService=createClientService(context);
<Line#92>    clientService.init(conf);
<Line#93>    containerAllocator=createContainerAllocator(clientService,context);
<Line#94>    committerEventHandler=createCommitterEventHandler(context,committer);
<Line#95>    addIfService(committerEventHandler);
<Line#96>    callWithJobClassLoader(conf,new Action<Void>(){
<Line#97>      public Void call(      Configuration conf){
<Line#98>        preemptionPolicy=createPreemptionPolicy(conf);
<Line#99>        preemptionPolicy.init(context);
<Line#100>        return null;
<Line#101>      }
<Line#102>    }
<Line#103>);
<Line#104>    taskAttemptListener=createTaskAttemptListener(context,preemptionPolicy);
<Line#105>    addIfService(taskAttemptListener);
<Line#106>    EventHandler<JobHistoryEvent> historyService=createJobHistoryHandler(context);
<Line#107>    dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,historyService);
<Line#108>    this.jobEventDispatcher=new JobEventDispatcher();
<Line#109>    dispatcher.register(JobEventType.class,jobEventDispatcher);
<Line#110>    dispatcher.register(TaskEventType.class,new TaskEventDispatcher());
<Line#111>    dispatcher.register(TaskAttemptEventType.class,new TaskAttemptEventDispatcher());
<Line#112>    dispatcher.register(CommitterEventType.class,committerEventHandler);
<Line#113>    if (conf.getBoolean(MRJobConfig.MAP_SPECULATIVE,false) || conf.getBoolean(MRJobConfig.REDUCE_SPECULATIVE,false)) {
<Line#114>      speculator=createSpeculator(conf,context);
<Line#115>      addIfService(speculator);
<Line#116>    }
<Line#117>    speculatorEventDispatcher=new SpeculatorEventDispatcher(conf);
<Line#118>    dispatcher.register(Speculator.EventType.class,speculatorEventDispatcher);
<Line#119>    addService(createStagingDirCleaningService());
<Line#120>    addIfService(containerAllocator);
<Line#121>    dispatcher.register(ContainerAllocator.EventType.class,containerAllocator);
<Line#122>    containerLauncher=createContainerLauncher(context);
<Line#123>    addIfService(containerLauncher);
<Line#124>    dispatcher.register(ContainerLauncher.EventType.class,containerLauncher);
<Line#125>    addIfService(historyService);
<Line#126>  }
<Line#127>  super.serviceInit(conf);
<Line#128>}
Label: <Line#33> LOG.info("Attempt num: " + appAttemptID.getAttemptId() + " is last retry: "+ isLastAMRetry+ " because the staging dir doesn't exist.")

Example 5:
<Line#1>{
<Line#2>  createJobClassLoader(conf);
<Line#3>  initJobCredentialsAndUGI(conf);
<Line#4>  dispatcher=createDispatcher();
<Line#5>  addIfService(dispatcher);
<Line#6>  taskAttemptFinishingMonitor=createTaskAttemptFinishingMonitor(dispatcher.getEventHandler());
<Line#7>  addIfService(taskAttemptFinishingMonitor);
<Line#8>  context=new RunningAppContext(conf,taskAttemptFinishingMonitor);
<Line#9>  appName=conf.get(MRJobConfig.JOB_NAME,"<missing app name>");
<Line#10>  conf.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,appAttemptID.getAttemptId());
<Line#11>  newApiCommitter=false;
<Line#12>  jobId=MRBuilderUtils.newJobId(appAttemptID.getApplicationId(),appAttemptID.getApplicationId().getId());
<Line#13>  int numReduceTasks=conf.getInt(MRJobConfig.NUM_REDUCES,0);
<Line#14>  if ((numReduceTasks > 0 && conf.getBoolean("mapred.reducer.new-api",false)) || (numReduceTasks == 0 && conf.getBoolean("mapred.mapper.new-api",false))) {
<Line#15>    newApiCommitter=true;
<Line#16>    LOG.info("Using mapred newApiCommitter.");
<Line#17>  }
<Line#18>  boolean copyHistory=false;
<Line#19>  committer=createOutputCommitter(conf);
<Line#20>  try {
<Line#21>    String user=UserGroupInformation.getCurrentUser().getShortUserName();
<Line#22>    Path stagingDir=MRApps.getStagingAreaDir(conf,user);
<Line#23>    FileSystem fs=getFileSystem(conf);
<Line#24>    boolean stagingExists=fs.exists(stagingDir);
<Line#25>    Path startCommitFile=MRApps.getStartJobCommitFile(conf,user,jobId);
<Line#26>    boolean commitStarted=fs.exists(startCommitFile);
<Line#27>    Path endCommitSuccessFile=MRApps.getEndJobCommitSuccessFile(conf,user,jobId);
<Line#28>    boolean commitSuccess=fs.exists(endCommitSuccessFile);
<Line#29>    Path endCommitFailureFile=MRApps.getEndJobCommitFailureFile(conf,user,jobId);
<Line#30>    boolean commitFailure=fs.exists(endCommitFailureFile);
<Line#31>    if (!stagingExists) {
<Line#32>      isLastAMRetry=true;
<Line#33>      LOG.info("Attempt num: " + appAttemptID.getAttemptId() + " is last retry: "+ isLastAMRetry+ " because the staging dir doesn't exist.");
<Line#34>      errorHappenedShutDown=true;
<Line#35>      forcedState=JobStateInternal.ERROR;
<Line#36>      shutDownMessage="Staging dir does not exist " + stagingDir;
<Line#37>      LOG.error(shutDownMessage);
<Line#38>    }
<Line#39> else     if (commitStarted) {
<Line#40>      errorHappenedShutDown=true;
<Line#41>      isLastAMRetry=true;
<Line#42>      LOG.info("Attempt num: " + appAttemptID.getAttemptId() + " is last retry: "+ isLastAMRetry+ " because a commit was started.");
<Line#43>      copyHistory=true;
<Line#44>      if (commitSuccess) {
<Line#45>        shutDownMessage="Job commit succeeded in a prior MRAppMaster attempt " + "before it crashed. Recovering.";
<Line#46>        forcedState=JobStateInternal.SUCCEEDED;
<Line#47>      }
<Line#48> else       if (commitFailure) {
<Line#49>        shutDownMessage="Job commit failed in a prior MRAppMaster attempt " + "before it crashed. Not retrying.";
<Line#50>        forcedState=JobStateInternal.FAILED;
<Line#51>      }
<Line#52> else {
<Line#53>        if (isCommitJobRepeatable()) {
<Line#54>          errorHappenedShutDown=false;
<Line#55>          cleanupInterruptedCommit(conf,fs,startCommitFile);
<Line#56>        }
<Line#57> else {
<Line#58>          shutDownMessage="Job commit from a prior MRAppMaster attempt is " + "potentially in progress. Preventing multiple commit executions";
<Line#59>          forcedState=JobStateInternal.ERROR;
<Line#60>        }
<Line#61>      }
<Line#62>    }
<Line#63>  }
<Line#64> catch (  IOException e) {
<Line#65>    throw new YarnRuntimeException("Error while initializing",e);
<Line#66>  }
<Line#67>  if (errorHappenedShutDown) {
<Line#68>    NoopEventHandler eater=new NoopEventHandler();
<Line#69>    dispatcher.register(JobEventType.class,eater);
<Line#70>    EventHandler<JobHistoryEvent> historyService=null;
<Line#71>    if (copyHistory) {
<Line#72>      historyService=createJobHistoryHandler(context);
<Line#73>      dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,historyService);
<Line#74>    }
<Line#75> else {
<Line#76>      dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,eater);
<Line#77>    }
<Line#78>    if (copyHistory) {
<Line#79>      addService(createStagingDirCleaningService());
<Line#80>    }
<Line#81>    containerAllocator=createContainerAllocator(null,context);
<Line#82>    addIfService(containerAllocator);
<Line#83>    dispatcher.register(ContainerAllocator.EventType.class,containerAllocator);
<Line#84>    if (copyHistory) {
<Line#85>      addIfService(historyService);
<Line#86>      JobHistoryCopyService cpHist=new JobHistoryCopyService(appAttemptID,dispatcher.getEventHandler());
<Line#87>      addIfService(cpHist);
<Line#88>    }
<Line#89>  }
<Line#90> else {
<Line#91>    clientService=createClientService(context);
<Line#92>    clientService.init(conf);
<Line#93>    containerAllocator=createContainerAllocator(clientService,context);
<Line#94>    committerEventHandler=createCommitterEventHandler(context,committer);
<Line#95>    addIfService(committerEventHandler);
<Line#96>    callWithJobClassLoader(conf,new Action<Void>(){
<Line#97>      public Void call(      Configuration conf){
<Line#98>        preemptionPolicy=createPreemptionPolicy(conf);
<Line#99>        preemptionPolicy.init(context);
<Line#100>        return null;
<Line#101>      }
<Line#102>    }
<Line#103>);
<Line#104>    taskAttemptListener=createTaskAttemptListener(context,preemptionPolicy);
<Line#105>    addIfService(taskAttemptListener);
<Line#106>    EventHandler<JobHistoryEvent> historyService=createJobHistoryHandler(context);
<Line#107>    dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,historyService);
<Line#108>    this.jobEventDispatcher=new JobEventDispatcher();
<Line#109>    dispatcher.register(JobEventType.class,jobEventDispatcher);
<Line#110>    dispatcher.register(TaskEventType.class,new TaskEventDispatcher());
<Line#111>    dispatcher.register(TaskAttemptEventType.class,new TaskAttemptEventDispatcher());
<Line#112>    dispatcher.register(CommitterEventType.class,committerEventHandler);
<Line#113>    if (conf.getBoolean(MRJobConfig.MAP_SPECULATIVE,false) || conf.getBoolean(MRJobConfig.REDUCE_SPECULATIVE,false)) {
<Line#114>      speculator=createSpeculator(conf,context);
<Line#115>      addIfService(speculator);
<Line#116>    }
<Line#117>    speculatorEventDispatcher=new SpeculatorEventDispatcher(conf);
<Line#118>    dispatcher.register(Speculator.EventType.class,speculatorEventDispatcher);
<Line#119>    addService(createStagingDirCleaningService());
<Line#120>    addIfService(containerAllocator);
<Line#121>    dispatcher.register(ContainerAllocator.EventType.class,containerAllocator);
<Line#122>    containerLauncher=createContainerLauncher(context);
<Line#123>    addIfService(containerLauncher);
<Line#124>    dispatcher.register(ContainerLauncher.EventType.class,containerLauncher);
<Line#125>    addIfService(historyService);
<Line#126>  }
<Line#127>  super.serviceInit(conf);
<Line#128>}
Label: <Line#37> LOG.error(shutDownMessage)

