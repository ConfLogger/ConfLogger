select <line#> and insert log level and Log verbosity message after <line#>

Query: Target method code:
<Line#0>void activate(Configuration conf) {
<Line#1>final int intervalSecs = (int) conf.getTimeDuration(
<Line#2>DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_INTERVAL_KEY,
<Line#3>DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_INTERVAL_DEFAULT,
<Line#4>TimeUnit.SECONDS);
<Line#5>checkArgument(intervalSecs >= 0, "Cannot set a negative " +
<Line#6>"value for " + DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_INTERVAL_KEY);
<Line#7>
<Line#8>int blocksPerInterval = conf.getInt(
<Line#9>DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_BLOCKS_PER_INTERVAL_KEY,
<Line#10>DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_BLOCKS_PER_INTERVAL_DEFAULT);
<Line#11>
<Line#12>final String deprecatedKey =
<Line#13>"dfs.namenode.decommission.nodes.per.interval";
<Line#14>final String strNodes = conf.get(deprecatedKey);
<Line#15>if (strNodes != null) {
<Line#16>;
<Line#17>}
<Line#18>
<Line#19>checkArgument(blocksPerInterval > 0,
<Line#20>"Must set a positive value for "
<Line#21>+ DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_BLOCKS_PER_INTERVAL_KEY);
<Line#22>
<Line#23>final int maxConcurrentTrackedNodes = conf.getInt(
<Line#24>DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_MAX_CONCURRENT_TRACKED_NODES,
<Line#25>DFSConfigKeys
<Line#26>.DFS_NAMENODE_DECOMMISSION_MAX_CONCURRENT_TRACKED_NODES_DEFAULT);
<Line#27>checkArgument(maxConcurrentTrackedNodes >= 0, "Cannot set a negative " +
<Line#28>"value for "
<Line#29>+ DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_MAX_CONCURRENT_TRACKED_NODES);
<Line#30>
<Line#31>Class cls = null;
<Line#32>try {
<Line#33>cls = conf.getClass(
<Line#34>DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_MONITOR_CLASS,
<Line#35>DatanodeAdminDefaultMonitor.class);
<Line#36>monitor =
<Line#37>(DatanodeAdminMonitorInterface)ReflectionUtils.newInstance(cls, conf);
<Line#38>monitor.setBlockManager(blockManager);
<Line#39>monitor.setNameSystem(namesystem);
<Line#40>monitor.setDatanodeAdminManager(this);
<Line#41>} catch (Exception e) {
<Line#42>throw new RuntimeException("Unable to create the Decommission monitor " +
<Line#43>"from "+cls, e);
<Line#44>}
<Line#45>executor.scheduleWithFixedDelay(monitor, intervalSecs, intervalSecs,
<Line#46>TimeUnit.SECONDS);
<Line#47>
<Line#48>LOG.debug("Activating DatanodeAdminManager with interval {} seconds, " +
<Line#49>"{} max blocks per interval, " +
<Line#50>"{} max concurrently tracked nodes.", intervalSecs,
<Line#51>blocksPerInterval, maxConcurrentTrackedNodes);
<Line#52>}

Example 1:
<Line#1>{
<Line#2>  boolean success=false;
<Line#3>  try {
<Line#4>    ExitUtil.disableSystemExit();
<Line#5>    FileSystem.enableSymlinks();
<Line#6>synchronized (MiniDFSCluster.class) {
<Line#7>      instanceId=instanceCount++;
<Line#8>    }
<Line#9>    this.conf=conf;
<Line#10>    base_dir=new File(determineDfsBaseDir());
<Line#11>    data_dir=new File(base_dir,"data");
<Line#12>    this.waitSafeMode=waitSafeMode;
<Line#13>    this.checkExitOnShutdown=checkExitOnShutdown;
<Line#14>    int replication=conf.getInt(DFS_REPLICATION_KEY,3);
<Line#15>    conf.setInt(DFS_REPLICATION_KEY,Math.min(replication,numDataNodes));
<Line#16>    int maintenanceMinReplication=conf.getInt(DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_KEY,DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_DEFAULT);
<Line#17>    if (maintenanceMinReplication == DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_DEFAULT) {
<Line#18>      conf.setInt(DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_KEY,Math.min(maintenanceMinReplication,numDataNodes));
<Line#19>    }
<Line#20>    int safemodeExtension=conf.getInt(DFS_NAMENODE_SAFEMODE_EXTENSION_TESTING_KEY,0);
<Line#21>    conf.setInt(DFS_NAMENODE_SAFEMODE_EXTENSION_KEY,safemodeExtension);
<Line#22>    long decommissionInterval=conf.getTimeDuration(DFS_NAMENODE_DECOMMISSION_INTERVAL_TESTING_KEY,3,TimeUnit.SECONDS);
<Line#23>    conf.setTimeDuration(DFS_NAMENODE_DECOMMISSION_INTERVAL_KEY,decommissionInterval,TimeUnit.SECONDS);
<Line#24>    if (!useConfiguredTopologyMappingClass) {
<Line#25>      conf.setClass(NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY,StaticMapping.class,DNSToSwitchMapping.class);
<Line#26>    }
<Line#27>    if (!nnTopology.allHttpPortsSpecified() && nnTopology.isHA()) {
<Line#28>      LOG.info("MiniDFSCluster disabling checkpointing in the Standby node " + "since no HTTP ports have been specified.");
<Line#29>      conf.setBoolean(DFS_HA_STANDBY_CHECKPOINTS_KEY,false);
<Line#30>    }
<Line#31>    if (!nnTopology.allIpcPortsSpecified() && nnTopology.isHA()) {
<Line#32>      LOG.info("MiniDFSCluster disabling log-roll triggering in the " + "Standby node since no IPC ports have been specified.");
<Line#33>      conf.setInt(DFS_HA_LOGROLL_PERIOD_KEY,-1);
<Line#34>    }
<Line#35>    EditLogFileOutputStream.setShouldSkipFsyncForTesting(skipFsyncForTesting);
<Line#36>    federation=nnTopology.isFederated();
<Line#37>    try {
<Line#38>      createNameNodesAndSetConf(nnTopology,manageNameDfsDirs,manageNameDfsSharedDirs,enableManagedDfsDirsRedundancy,format,startOpt,clusterId);
<Line#39>    }
<Line#40> catch (    IOException ioe) {
<Line#41>      LOG.error("IOE creating namenodes. Permissions dump:\n" + createPermissionsDiagnosisString(data_dir),ioe);
<Line#42>      throw ioe;
<Line#43>    }
<Line#44>    if (format) {
<Line#45>      if (data_dir.exists() && !FileUtil.fullyDelete(data_dir)) {
<Line#46>        throw new IOException("Cannot remove data directory: " + data_dir + createPermissionsDiagnosisString(data_dir));
<Line#47>      }
<Line#48>    }
<Line#49>    if (startOpt == StartupOption.RECOVER) {
<Line#50>      return;
<Line#51>    }
<Line#52>    startDataNodes(conf,numDataNodes,storageTypes,manageDataDfsDirs,dnStartOpt != null ? dnStartOpt : startOpt,racks,hosts,storageCapacities,simulatedCapacities,setupHostsFile,checkDataNodeAddrConfig,checkDataNodeHostConfig,dnConfOverlays,dnHttpPorts,dnIpcPorts);
<Line#53>    waitClusterUp();
<Line#54>    ProxyUsers.refreshSuperUserGroupsConfiguration(conf);
<Line#55>    success=true;
<Line#56>  }
<Line#57>  finally {
<Line#58>    if (!success) {
<Line#59>      shutdown();
<Line#60>    }
<Line#61>  }
<Line#62>}
Label: <Line#28> LOG.info("MiniDFSCluster disabling checkpointing in the Standby node " + "since no HTTP ports have been specified.")

Example 2:
<Line#1>{
<Line#2>  boolean success=false;
<Line#3>  try {
<Line#4>    ExitUtil.disableSystemExit();
<Line#5>    FileSystem.enableSymlinks();
<Line#6>synchronized (MiniDFSCluster.class) {
<Line#7>      instanceId=instanceCount++;
<Line#8>    }
<Line#9>    this.conf=conf;
<Line#10>    base_dir=new File(determineDfsBaseDir());
<Line#11>    data_dir=new File(base_dir,"data");
<Line#12>    this.waitSafeMode=waitSafeMode;
<Line#13>    this.checkExitOnShutdown=checkExitOnShutdown;
<Line#14>    int replication=conf.getInt(DFS_REPLICATION_KEY,3);
<Line#15>    conf.setInt(DFS_REPLICATION_KEY,Math.min(replication,numDataNodes));
<Line#16>    int maintenanceMinReplication=conf.getInt(DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_KEY,DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_DEFAULT);
<Line#17>    if (maintenanceMinReplication == DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_DEFAULT) {
<Line#18>      conf.setInt(DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_KEY,Math.min(maintenanceMinReplication,numDataNodes));
<Line#19>    }
<Line#20>    int safemodeExtension=conf.getInt(DFS_NAMENODE_SAFEMODE_EXTENSION_TESTING_KEY,0);
<Line#21>    conf.setInt(DFS_NAMENODE_SAFEMODE_EXTENSION_KEY,safemodeExtension);
<Line#22>    long decommissionInterval=conf.getTimeDuration(DFS_NAMENODE_DECOMMISSION_INTERVAL_TESTING_KEY,3,TimeUnit.SECONDS);
<Line#23>    conf.setTimeDuration(DFS_NAMENODE_DECOMMISSION_INTERVAL_KEY,decommissionInterval,TimeUnit.SECONDS);
<Line#24>    if (!useConfiguredTopologyMappingClass) {
<Line#25>      conf.setClass(NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY,StaticMapping.class,DNSToSwitchMapping.class);
<Line#26>    }
<Line#27>    if (!nnTopology.allHttpPortsSpecified() && nnTopology.isHA()) {
<Line#28>      LOG.info("MiniDFSCluster disabling checkpointing in the Standby node " + "since no HTTP ports have been specified.");
<Line#29>      conf.setBoolean(DFS_HA_STANDBY_CHECKPOINTS_KEY,false);
<Line#30>    }
<Line#31>    if (!nnTopology.allIpcPortsSpecified() && nnTopology.isHA()) {
<Line#32>      LOG.info("MiniDFSCluster disabling log-roll triggering in the " + "Standby node since no IPC ports have been specified.");
<Line#33>      conf.setInt(DFS_HA_LOGROLL_PERIOD_KEY,-1);
<Line#34>    }
<Line#35>    EditLogFileOutputStream.setShouldSkipFsyncForTesting(skipFsyncForTesting);
<Line#36>    federation=nnTopology.isFederated();
<Line#37>    try {
<Line#38>      createNameNodesAndSetConf(nnTopology,manageNameDfsDirs,manageNameDfsSharedDirs,enableManagedDfsDirsRedundancy,format,startOpt,clusterId);
<Line#39>    }
<Line#40> catch (    IOException ioe) {
<Line#41>      LOG.error("IOE creating namenodes. Permissions dump:\n" + createPermissionsDiagnosisString(data_dir),ioe);
<Line#42>      throw ioe;
<Line#43>    }
<Line#44>    if (format) {
<Line#45>      if (data_dir.exists() && !FileUtil.fullyDelete(data_dir)) {
<Line#46>        throw new IOException("Cannot remove data directory: " + data_dir + createPermissionsDiagnosisString(data_dir));
<Line#47>      }
<Line#48>    }
<Line#49>    if (startOpt == StartupOption.RECOVER) {
<Line#50>      return;
<Line#51>    }
<Line#52>    startDataNodes(conf,numDataNodes,storageTypes,manageDataDfsDirs,dnStartOpt != null ? dnStartOpt : startOpt,racks,hosts,storageCapacities,simulatedCapacities,setupHostsFile,checkDataNodeAddrConfig,checkDataNodeHostConfig,dnConfOverlays,dnHttpPorts,dnIpcPorts);
<Line#53>    waitClusterUp();
<Line#54>    ProxyUsers.refreshSuperUserGroupsConfiguration(conf);
<Line#55>    success=true;
<Line#56>  }
<Line#57>  finally {
<Line#58>    if (!success) {
<Line#59>      shutdown();
<Line#60>    }
<Line#61>  }
<Line#62>}
Label: <Line#32> LOG.info("MiniDFSCluster disabling log-roll triggering in the " + "Standby node since no IPC ports have been specified.")

Example 3:
<Line#1>{
<Line#2>  boolean success=false;
<Line#3>  try {
<Line#4>    ExitUtil.disableSystemExit();
<Line#5>    FileSystem.enableSymlinks();
<Line#6>synchronized (MiniDFSCluster.class) {
<Line#7>      instanceId=instanceCount++;
<Line#8>    }
<Line#9>    this.conf=conf;
<Line#10>    base_dir=new File(determineDfsBaseDir());
<Line#11>    data_dir=new File(base_dir,"data");
<Line#12>    this.waitSafeMode=waitSafeMode;
<Line#13>    this.checkExitOnShutdown=checkExitOnShutdown;
<Line#14>    int replication=conf.getInt(DFS_REPLICATION_KEY,3);
<Line#15>    conf.setInt(DFS_REPLICATION_KEY,Math.min(replication,numDataNodes));
<Line#16>    int maintenanceMinReplication=conf.getInt(DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_KEY,DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_DEFAULT);
<Line#17>    if (maintenanceMinReplication == DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_DEFAULT) {
<Line#18>      conf.setInt(DFSConfigKeys.DFS_NAMENODE_MAINTENANCE_REPLICATION_MIN_KEY,Math.min(maintenanceMinReplication,numDataNodes));
<Line#19>    }
<Line#20>    int safemodeExtension=conf.getInt(DFS_NAMENODE_SAFEMODE_EXTENSION_TESTING_KEY,0);
<Line#21>    conf.setInt(DFS_NAMENODE_SAFEMODE_EXTENSION_KEY,safemodeExtension);
<Line#22>    long decommissionInterval=conf.getTimeDuration(DFS_NAMENODE_DECOMMISSION_INTERVAL_TESTING_KEY,3,TimeUnit.SECONDS);
<Line#23>    conf.setTimeDuration(DFS_NAMENODE_DECOMMISSION_INTERVAL_KEY,decommissionInterval,TimeUnit.SECONDS);
<Line#24>    if (!useConfiguredTopologyMappingClass) {
<Line#25>      conf.setClass(NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY,StaticMapping.class,DNSToSwitchMapping.class);
<Line#26>    }
<Line#27>    if (!nnTopology.allHttpPortsSpecified() && nnTopology.isHA()) {
<Line#28>      LOG.info("MiniDFSCluster disabling checkpointing in the Standby node " + "since no HTTP ports have been specified.");
<Line#29>      conf.setBoolean(DFS_HA_STANDBY_CHECKPOINTS_KEY,false);
<Line#30>    }
<Line#31>    if (!nnTopology.allIpcPortsSpecified() && nnTopology.isHA()) {
<Line#32>      LOG.info("MiniDFSCluster disabling log-roll triggering in the " + "Standby node since no IPC ports have been specified.");
<Line#33>      conf.setInt(DFS_HA_LOGROLL_PERIOD_KEY,-1);
<Line#34>    }
<Line#35>    EditLogFileOutputStream.setShouldSkipFsyncForTesting(skipFsyncForTesting);
<Line#36>    federation=nnTopology.isFederated();
<Line#37>    try {
<Line#38>      createNameNodesAndSetConf(nnTopology,manageNameDfsDirs,manageNameDfsSharedDirs,enableManagedDfsDirsRedundancy,format,startOpt,clusterId);
<Line#39>    }
<Line#40> catch (    IOException ioe) {
<Line#41>      LOG.error("IOE creating namenodes. Permissions dump:\n" + createPermissionsDiagnosisString(data_dir),ioe);
<Line#42>      throw ioe;
<Line#43>    }
<Line#44>    if (format) {
<Line#45>      if (data_dir.exists() && !FileUtil.fullyDelete(data_dir)) {
<Line#46>        throw new IOException("Cannot remove data directory: " + data_dir + createPermissionsDiagnosisString(data_dir));
<Line#47>      }
<Line#48>    }
<Line#49>    if (startOpt == StartupOption.RECOVER) {
<Line#50>      return;
<Line#51>    }
<Line#52>    startDataNodes(conf,numDataNodes,storageTypes,manageDataDfsDirs,dnStartOpt != null ? dnStartOpt : startOpt,racks,hosts,storageCapacities,simulatedCapacities,setupHostsFile,checkDataNodeAddrConfig,checkDataNodeHostConfig,dnConfOverlays,dnHttpPorts,dnIpcPorts);
<Line#53>    waitClusterUp();
<Line#54>    ProxyUsers.refreshSuperUserGroupsConfiguration(conf);
<Line#55>    success=true;
<Line#56>  }
<Line#57>  finally {
<Line#58>    if (!success) {
<Line#59>      shutdown();
<Line#60>    }
<Line#61>  }
<Line#62>}
Label: <Line#41> LOG.error("IOE creating namenodes. Permissions dump:\n" + createPermissionsDiagnosisString(data_dir),ioe)

Example 4:
<Line#1>{
<Line#2>  final DDatanode targetDn=p.target.getDDatanode();
<Line#3>  ExecutorService moveExecutor=targetDn.getMoveExecutor();
<Line#4>  if (moveExecutor == null) {
<Line#5>    final int nThreads=moverThreadAllocator.allocate();
<Line#6>    if (nThreads > 0) {
<Line#7>      moveExecutor=targetDn.initMoveExecutor(nThreads);
<Line#8>    }
<Line#9>  }
<Line#10>  if (moveExecutor == null) {
<Line#11>    LOG.warn("No mover threads available: skip moving " + p);
<Line#12>    targetDn.removePendingBlock(p);
<Line#13>    p.proxySource.removePendingBlock(p);
<Line#14>    return;
<Line#15>  }
<Line#16>  moveExecutor.execute(new Runnable(){
<Line#17>    @Override public void run(){
<Line#18>      p.dispatch();
<Line#19>    }
<Line#20>  }
<Line#21>);
<Line#22>}
Label: <Line#11> LOG.warn("No mover threads available: skip moving " + p)

Example 5:
<Line#1>{
<Line#2>  LOG.info(this + " starting to offer service");
<Line#3>  try {
<Line#4>    while (true) {
<Line#5>      try {
<Line#6>        connectToNNAndHandshake();
<Line#7>        break;
<Line#8>      }
<Line#9> catch (      IOException ioe) {
<Line#10>        runningState=RunningState.INIT_FAILED;
<Line#11>        if (shouldRetryInit()) {
<Line#12>          LOG.error("Initialization failed for " + this + " "+ ioe.getLocalizedMessage());
<Line#13>          sleepAndLogInterrupts(5000,"initializing");
<Line#14>        }
<Line#15> else {
<Line#16>          runningState=RunningState.FAILED;
<Line#17>          LOG.error("Initialization failed for " + this + ". Exiting. ",ioe);
<Line#18>          return;
<Line#19>        }
<Line#20>      }
<Line#21>    }
<Line#22>    runningState=RunningState.RUNNING;
<Line#23>    if (initialRegistrationComplete != null) {
<Line#24>      initialRegistrationComplete.countDown();
<Line#25>    }
<Line#26>    ibrExecutorService.submit(new IBRTaskHandler());
<Line#27>    while (shouldRun()) {
<Line#28>      try {
<Line#29>        offerService();
<Line#30>      }
<Line#31> catch (      Exception ex) {
<Line#32>        LOG.error("Exception in BPOfferService for " + this,ex);
<Line#33>        sleepAndLogInterrupts(5000,"offering service");
<Line#34>      }
<Line#35>    }
<Line#36>    runningState=RunningState.EXITED;
<Line#37>  }
<Line#38> catch (  Throwable ex) {
<Line#39>    LOG.warn("Unexpected exception in block pool " + this,ex);
<Line#40>    runningState=RunningState.FAILED;
<Line#41>  }
<Line#42> finally {
<Line#43>    LOG.warn("Ending block pool service for: " + this);
<Line#44>    cleanUp();
<Line#45>  }
<Line#46>}
Label: <Line#2> LOG.info(this + " starting to offer service")

