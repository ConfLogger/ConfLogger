Insert a logging statement to the following code using <API>. Format: <Line#X>:# <Statement>:#

Target Code:
<Line#0> private List<InetSocketAddress> getOtherJournalNodeAddrs() {
<Line#1> String uriStr = "";
<Line#2> try {
<Line#3> uriStr = conf.getTrimmed(DFSConfigKeys.DFS_NAMENODE_SHARED_EDITS_DIR_KEY);
<Line#4> 
<Line#5> if (uriStr == null || uriStr.isEmpty()) {
<Line#6> if (nameServiceId != null) {
<Line#7> uriStr = conf.getTrimmed(DFSConfigKeys
<Line#8> .DFS_NAMENODE_SHARED_EDITS_DIR_KEY + "." + nameServiceId);
<Line#9> }
<Line#10> }
<Line#11> 
<Line#12> if (uriStr == null || uriStr.isEmpty()) {
<Line#13> HashSet<String> sharedEditsUri = Sets.newHashSet();
<Line#14> if (nameServiceId != null) {
<Line#15> Collection<String> nnIds = DFSUtilClient.getNameNodeIds(
<Line#16> conf, nameServiceId);
<Line#17> for (String nnId : nnIds) {
<Line#18> String suffix = nameServiceId + "." + nnId;
<Line#19> uriStr = conf.getTrimmed(DFSConfigKeys
<Line#20> .DFS_NAMENODE_SHARED_EDITS_DIR_KEY + "." + suffix);
<Line#21> sharedEditsUri.add(uriStr);
<Line#22> }
<Line#23> if (sharedEditsUri.size() > 1) {
<Line#24> uriStr = null;
<Line#25> }
<Line#26> }
<Line#27> }
<Line#28> 
<Line#29> if (uriStr == null || uriStr.isEmpty()) {
<Line#30> return null;
<Line#31> } else {
<Line#32> return getJournalAddrList(uriStr);
<Line#33> }
<Line#34> 
<Line#35> } catch (URISyntaxException e) {
<Line#36> } catch (IOException e) {
<Line#37> }
<Line#38> return null;
<Line#39> }

Related Context:
Method A:
<Line#0> @VisibleForTesting protected List<InetSocketAddress> getJournalAddrList(String uriStr) throws URISyntaxException, IOException {
<Line#1>   URI uri=new URI(uriStr);
<Line#2>   InetSocketAddress boundIpcAddress=jn.getBoundIpcAddress();
<Line#3>   Set<InetSocketAddress> excluded=Sets.newHashSet(boundIpcAddress);
<Line#4>   List<InetSocketAddress> addrList=Util.getLoggerAddresses(uri,excluded);
<Line#5>   addrList.removeIf(addr -> !addr.isUnresolved() && addr.getAddress().isAnyLocalAddress() && boundIpcAddress.getPort() == addr.getPort());
<Line#6>   return addrList;
<Line#7> }
<Line#8> 
Method B:
<Line#0> /** 
<Line#1>  * Add non empty and non null suffix to a key 
<Line#2>  */
<Line#3> static String addSuffix(String key,String suffix){
<Line#4> }
<Line#5> 

Relevant Logging Patterns:
Example 1:
File: hdfs__breakHardlinks-183__.json
Code:
<Line#1>{
<Line#2>  final FileIoProvider fileIoProvider=getFileIoProvider();
<Line#3>  final File tmpFile=DatanodeUtil.createFileWithExistsCheck(getVolume(),b,DatanodeUtil.getUnlinkTmpFile(file),fileIoProvider);
<Line#4>  try {
<Line#5>    try (FileInputStream in=fileIoProvider.getFileInputStream(getVolume(),file)){
<Line#6>      try (FileOutputStream out=fileIoProvider.getFileOutputStream(getVolume(),tmpFile)){
<Line#7>        IOUtils.copyBytes(in,out,16 * 1024);
<Line#8>      }
<Line#9>     }
<Line#10>     if (file.length() != tmpFile.length()) {
<Line#11>      throw new IOException("Copy of file " + file + " size "+ file.length()+ " into file "+ tmpFile+ " resulted in a size of "+ tmpFile.length());
<Line#12>    }
<Line#13>    fileIoProvider.replaceFile(getVolume(),tmpFile,file);
<Line#14>  }
<Line#15> catch (  IOException e) {
<Line#16>    if (!fileIoProvider.delete(getVolume(),tmpFile)) {
<Line#17>      DataNode.LOG.info("detachFile failed to delete temporary file " + tmpFile);
<Line#18>    }
<Line#19>    throw e;
<Line#20>  }
<Line#21>}
Log: <Line#17>:# DataNode.LOG.info("detachFile failed to delete temporary file " + tmpFile):#

Example 2:
File: hdfs__cancelDelegationToken-766__.json
Code:
<Line#1>{
<Line#2>  LOG.info("Cancelling " + DelegationTokenIdentifier.stringifyToken(token));
<Line#3>  try {
<Line#4>    token.cancel(conf);
<Line#5>  }
<Line#6> catch (  InterruptedException ie) {
<Line#7>    throw new RuntimeException("caught interrupted",ie);
<Line#8>  }
<Line#9>catch (  RemoteException re) {
<Line#10>    throw re.unwrapRemoteException(InvalidToken.class,AccessControlException.class);
<Line#11>  }
<Line#12>}
Log: <Line#2>:# LOG.info("Cancelling " + DelegationTokenIdentifier.stringifyToken(token)):#

Example 3:
File: hdfs__verifyChunks-484__.json
Code:
<Line#1>{
<Line#2>  try {
<Line#3>    clientChecksum.verifyChunkedSums(dataBuf,checksumBuf,clientname,0);
<Line#4>  }
<Line#5> catch (  ChecksumException ce) {
<Line#6>    PacketHeader header=packetReceiver.getHeader();
<Line#7>    String specificOffset="specific offsets are:" + " offsetInBlock = " + header.getOffsetInBlock() + " offsetInPacket = "+ ce.getPos();
<Line#8>    LOG.warn("Checksum error in block " + block + " from "+ inAddr+ ", "+ specificOffset,ce);
<Line#9>    if (srcDataNode != null && isDatanode) {
<Line#10>      try {
<Line#11>        LOG.info("report corrupt " + block + " from datanode "+ srcDataNode+ " to namenode");
<Line#12>        datanode.reportRemoteBadBlock(srcDataNode,block);
<Line#13>      }
<Line#14> catch (      IOException e) {
<Line#15>        LOG.warn("Failed to report bad " + block + " from datanode "+ srcDataNode+ " to namenode");
<Line#16>      }
<Line#17>    }
<Line#18>    throw new IOException("Unexpected checksum mismatch while writing " + block + " from "+ inAddr);
<Line#19>  }
<Line#20>}
Log: <Line#8>:# LOG.warn("Checksum error in block " + block + " from "+ inAddr+ ", "+ specificOffset,ce):#

Example 4:
File: hdfs__verifyChunks-484__.json
Code:
<Line#1>{
<Line#2>  try {
<Line#3>    clientChecksum.verifyChunkedSums(dataBuf,checksumBuf,clientname,0);
<Line#4>  }
<Line#5> catch (  ChecksumException ce) {
<Line#6>    PacketHeader header=packetReceiver.getHeader();
<Line#7>    String specificOffset="specific offsets are:" + " offsetInBlock = " + header.getOffsetInBlock() + " offsetInPacket = "+ ce.getPos();
<Line#8>    LOG.warn("Checksum error in block " + block + " from "+ inAddr+ ", "+ specificOffset,ce);
<Line#9>    if (srcDataNode != null && isDatanode) {
<Line#10>      try {
<Line#11>        LOG.info("report corrupt " + block + " from datanode "+ srcDataNode+ " to namenode");
<Line#12>        datanode.reportRemoteBadBlock(srcDataNode,block);
<Line#13>      }
<Line#14> catch (      IOException e) {
<Line#15>        LOG.warn("Failed to report bad " + block + " from datanode "+ srcDataNode+ " to namenode");
<Line#16>      }
<Line#17>    }
<Line#18>    throw new IOException("Unexpected checksum mismatch while writing " + block + " from "+ inAddr);
<Line#19>  }
<Line#20>}
Log: <Line#11>:# LOG.info("report corrupt " + block + " from datanode "+ srcDataNode+ " to namenode"):#

Example 5:
File: hdfs__verifyChunks-484__.json
Code:
<Line#1>{
<Line#2>  try {
<Line#3>    clientChecksum.verifyChunkedSums(dataBuf,checksumBuf,clientname,0);
<Line#4>  }
<Line#5> catch (  ChecksumException ce) {
<Line#6>    PacketHeader header=packetReceiver.getHeader();
<Line#7>    String specificOffset="specific offsets are:" + " offsetInBlock = " + header.getOffsetInBlock() + " offsetInPacket = "+ ce.getPos();
<Line#8>    LOG.warn("Checksum error in block " + block + " from "+ inAddr+ ", "+ specificOffset,ce);
<Line#9>    if (srcDataNode != null && isDatanode) {
<Line#10>      try {
<Line#11>        LOG.info("report corrupt " + block + " from datanode "+ srcDataNode+ " to namenode");
<Line#12>        datanode.reportRemoteBadBlock(srcDataNode,block);
<Line#13>      }
<Line#14> catch (      IOException e) {
<Line#15>        LOG.warn("Failed to report bad " + block + " from datanode "+ srcDataNode+ " to namenode");
<Line#16>      }
<Line#17>    }
<Line#18>    throw new IOException("Unexpected checksum mismatch while writing " + block + " from "+ inAddr);
<Line#19>  }
<Line#20>}
Log: <Line#15>:# LOG.warn("Failed to report bad " + block + " from datanode "+ srcDataNode+ " to namenode"):#
